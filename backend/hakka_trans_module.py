import requests
import json
from dotenv import load_dotenv
import os
import re

load_dotenv()

def protect_markdown_symbols(text):
    """
    ä¿è­· Markdown æ ¼å¼ç¬¦è™Ÿï¼Œé¿å…ç¿»è­¯æ™‚è¢«ç ´å¢®
    ä½¿ç”¨ç‰¹æ®Š Unicode å­—ç¬¦ä½œç‚ºä¿è­·ç¬¦è™Ÿï¼Œé¿å…èˆ‡ Markdown æ ¼å¼è¡çª
    """
    protected_text = text
    
    # ç¬¬1æ­¥ï¼šä¿è­·ä»£ç¢¼å¡Šä½”ä½ç¬¦ï¼ˆæœ€é«˜å„ªå…ˆç´šï¼‰
    protected_text = re.sub(r'__CODE_BLOCK_(\d+)__', r'â¤CODE_BLOCK_\1â¤', protected_text)
    protected_text = re.sub(r'__TRANSLATE_PLACEHOLDER_(\d+)__', r'â¤TRANSLATE_PLACEHOLDER_\1â¤', protected_text)
    
    # ç¬¬2æ­¥ï¼šä¿è­·ç²—é«”æ ¼å¼ **text**
    protected_text = re.sub(r'\*\*(.+?)\*\*', r'â™¥BOLD_STARTâ™¥\1â™¥BOLD_ENDâ™¥', protected_text)
    
    # ç¬¬3æ­¥ï¼šä¿è­·åº•ç·šç²—é«” __text__ï¼ˆé¿å…èˆ‡ä»£ç¢¼å¡Šä½”ä½ç¬¦è¡çªï¼‰
    protected_text = re.sub(r'(?<!\w)__(.+?)__(?!\w)', r'â™¦UNDER_BOLD_STARTâ™¦\1â™¦UNDER_BOLD_ENDâ™¦', protected_text)
    
    # ç¬¬4æ­¥ï¼šä¿è­·æ–œé«”æ ¼å¼ *text* å’Œ _text_
    # æ›´ç²¾ç¢ºçš„æ–œé«”åŒ¹é…ï¼Œé¿å…èˆ‡å·²è™•ç†çš„ç²—é«”è¡çª
    protected_text = re.sub(r'(?<!â™¥)(?<!\*)\*([^*â™¥\s][^*â™¥]*?[^*â™¥\s])\*(?!\*)(?!â™¥)', r'â™£ITALIC_STARTâ™£\1â™£ITALIC_ENDâ™£', protected_text)
    protected_text = re.sub(r'(?<!â™¦)(?<!â™ )(?<!\w)_([^_â™¦â™ \s][^_â™¦â™ ]*?[^_â™¦â™ \s])_(?!\w)(?!â™¦)(?!â™ )', r'â™ UNDER_ITALIC_STARTâ™ \1â™ UNDER_ITALIC_ENDâ™ ', protected_text)
    
    return protected_text

def restore_markdown_symbols(text):
    """
    æ¢å¾© Markdown æ ¼å¼ç¬¦è™Ÿ
    å¢å¼·é­¯æ£’æ€§ï¼Œè™•ç†ç¿»è­¯APIå¯èƒ½é€ æˆçš„ç¬¦è™Ÿç ´å£
    """
    restored_text = text
    
    # ç¬¬1éšæ®µï¼šå˜—è©¦æ¢å¾©å®Œæ•´çš„ç¬¦è™Ÿçµ„åˆ
    # æ¢å¾©ä»£ç¢¼å¡Šä½”ä½ç¬¦ï¼ˆæœ€é«˜å„ªå…ˆç´šï¼‰
    restored_text = re.sub(r'â¤CODE_BLOCK_(\d+)â¤', r'__CODE_BLOCK_\1__', restored_text)
    restored_text = re.sub(r'â¤TRANSLATE_PLACEHOLDER_(\d+)â¤', r'__TRANSLATE_PLACEHOLDER_\1__', restored_text)
    
    # æ¢å¾©ç²—é«”æ ¼å¼
    restored_text = re.sub(r'â™¥BOLD_STARTâ™¥(.+?)â™¥BOLD_ENDâ™¥', r'**\1**', restored_text)
    
    # æ¢å¾©åº•ç·šç²—é«”
    restored_text = re.sub(r'â™¦UNDER_BOLD_STARTâ™¦(.+?)â™¦UNDER_BOLD_ENDâ™¦', r'__\1__', restored_text)
    
    # æ¢å¾©æ–œé«”æ ¼å¼
    restored_text = re.sub(r'â™£ITALIC_STARTâ™£(.+?)â™£ITALIC_ENDâ™£', r'*\1*', restored_text)
    restored_text = re.sub(r'â™ UNDER_ITALIC_STARTâ™ (.+?)â™ UNDER_ITALIC_ENDâ™ ', r'_\1_', restored_text)
    
    # ç¬¬2éšæ®µï¼šä¿®å¾©è¢«ç©ºæ ¼åˆ†é›¢çš„ç¬¦è™Ÿ
    # ä¿®å¾©è¢«ç©ºæ ¼åˆ†é›¢çš„ç²—é«”ç¬¦è™Ÿï¼ˆåŒ…æ‹¬æ’å…¥åº•ç·šçš„æƒ…æ³ï¼‰
    restored_text = re.sub(r'â™¥\s*BOLD\s*_?\s*START\s*â™¥', '**', restored_text)
    restored_text = re.sub(r'â™¥\s*BOLD\s*_?\s*END\s*â™¥', '**', restored_text)
    
    # ä¿®å¾©è¢«ç©ºæ ¼åˆ†é›¢çš„åº•ç·šç²—é«”ç¬¦è™Ÿ
    restored_text = re.sub(r'â™¦\s+UNDER\s*_?\s*BOLD\s*_?\s*START\s+â™¦', '__', restored_text)
    restored_text = re.sub(r'â™¦\s+UNDER\s*_?\s*BOLD\s*_?\s*END\s+â™¦', '__', restored_text)
    
    # ä¿®å¾©è¢«ç©ºæ ¼åˆ†é›¢çš„æ–œé«”ç¬¦è™Ÿ
    restored_text = re.sub(r'â™£\s+ITALIC\s*_?\s*START\s+â™£', '*', restored_text)
    restored_text = re.sub(r'â™£\s+ITALIC\s*_?\s*END\s+â™£', '*', restored_text)
    
    # ä¿®å¾©è¢«ç©ºæ ¼åˆ†é›¢çš„åº•ç·šæ–œé«”ç¬¦è™Ÿ
    restored_text = re.sub(r'â™ \s+UNDER\s*_?\s*ITALIC\s*_?\s*START\s+â™ ', '_', restored_text)
    restored_text = re.sub(r'â™ \s+UNDER\s*_?\s*ITALIC\s*_?\s*END\s+â™ ', '_', restored_text)
    
    # ä¿®å¾©è¢«ç©ºæ ¼åˆ†é›¢çš„ä»£ç¢¼å¡Šç¬¦è™Ÿï¼ˆåŒ…æ‹¬å„ç¨®ç ´å£æƒ…æ³ï¼‰
    restored_text = re.sub(r'â¤\s*CODE\s*_?\s*BLOCK\s*_?\s*(\d+)\s*â¤', r'__CODE_BLOCK_\1__', restored_text)
    restored_text = re.sub(r'â¤\s*CODE\s+BLOCK\s*_?\s*(\d+)\s*â¤', r'__CODE_BLOCK_\1__', restored_text)
    restored_text = re.sub(r'â¤\s*TRANSLATE\s*_?\s*PLACEHOLDER\s*_?\s*(\d+)\s*â¤', r'__TRANSLATE_PLACEHOLDER_\1__', restored_text)
    
    # ç¬¬3éšæ®µï¼šä¿®å¾©è¢«éƒ¨åˆ†ç ´å£çš„ç¬¦è™Ÿï¼ˆå­—æ¯è¢«åˆ†é›¢ï¼‰
    # ä¿®å¾© "B OLD" -> "BOLD" ç­‰æƒ…æ³
    restored_text = re.sub(r'â™¥\s*B\s+OLD\s*_?\s*START\s*â™¥', '**', restored_text)
    restored_text = re.sub(r'â™¥\s*B\s+OLD\s*_?\s*END\s*â™¥', '**', restored_text)
    
    # ä¿®å¾© "C ODE" -> "CODE" ç­‰æƒ…æ³
    restored_text = re.sub(r'â¤\s*C\s+ODE\s*_?\s*BLOCK\s*_?\s*(\d+)\s*â¤', r'__CODE_BLOCK_\1__', restored_text)
    
    # ä¿®å¾© "I TALIC" -> "ITALIC" ç­‰æƒ…æ³
    restored_text = re.sub(r'â™£\s*I\s+TALIC\s*_?\s*START\s*â™£', '*', restored_text)
    restored_text = re.sub(r'â™£\s*I\s+TALIC\s*_?\s*END\s*â™£', '*', restored_text)
    
    # ç¬¬4éšæ®µï¼šæ¸…ç†æ™®é€šçš„Markdownæ ¼å¼ç ´å£
    # ä¿®å¾©è¢«åˆ†é›¢çš„æ˜Ÿè™Ÿ
    restored_text = re.sub(r'\*\s+\*', '**', restored_text)
    # ä¿®å¾©è¢«åˆ†é›¢çš„åº•ç·š
    restored_text = re.sub(r'_\s+_', '__', restored_text)
    # ä¿®å¾©è¢«åˆ†é›¢çš„ä»£ç¢¼å¡Šæ¨™è¨˜
    restored_text = re.sub(r'_\s+_\s*CODE\s*_\s*BLOCK\s*_\s*(\d+)\s*_\s+_', r'__CODE_BLOCK_\1__', restored_text)
    
    # ç¬¬5éšæ®µï¼šç‰¹æ®Šçš„ä¸­æ–‡æ•¸å­—è½‰æ›å’Œä»£ç¢¼å¡Šä¿®å¾©
    # å…ˆå‰µå»ºä¸­æ–‡æ•¸å­—å°æ‡‰è¡¨
    chinese_numbers = {
        'ä¸€': '1', 'äºŒ': '2', 'ä¸‰': '3', 'å››': '4', 'äº”': '5',
        'å…­': '6', 'ä¸ƒ': '7', 'å…«': '8', 'ä¹': '9', 'å': '10',
        'åä¸€': '11', 'åäºŒ': '12'
    }
    
    # è™•ç†å„ç¨®è¢«ç ´å£çš„ä»£ç¢¼å¡Šæ ¼å¼
    # 1. è™•ç†ä¸­æ–‡æ•¸å­—çš„ä»£ç¢¼å¡Šï¼šâ¤CODE BLOCK_äºŒ â¤ -> __CODE_BLOCK_2__
    for chinese, arabic in chinese_numbers.items():
        restored_text = re.sub(f'â¤\s*CODE\s+BLOCK\s*_?\s*{chinese}\s*â¤', f'__CODE_BLOCK_{arabic}__', restored_text)
        restored_text = re.sub(f'â¤\s*CODE\s*_?\s*BLOCK\s*_?\s*{chinese}\s*â¤', f'__CODE_BLOCK_{arabic}__', restored_text)
    
    # 2. è™•ç†è¢«ç ´å£çš„ç‰¹æ®Šæ ¼å¼ï¼šâ¤CODE _BLOCK_å›› â¤
    for chinese, arabic in chinese_numbers.items():
        restored_text = re.sub(f'â¤\s*CODE\s+_\s*BLOCK\s*_?\s*{chinese}\s*â¤', f'__CODE_BLOCK_{arabic}__', restored_text)
        restored_text = re.sub(f'â¤\s*CODE\s*_\s*BLOCK\s*_?\s*{chinese}\s*â¤', f'__CODE_BLOCK_{arabic}__', restored_text)
    
    # 3. è™•ç†å…¶ä»–ç ´å¢®æ ¼å¼
    restored_text = re.sub(r'â¤\s*CODE\s*BLOCK\s*(\d+)\s*â¤', r'__CODE_BLOCK_\1__', restored_text)
    restored_text = re.sub(r'â¤\s*CODE\s+BLOCK\s*(\d+)\s*â¤', r'__CODE_BLOCK_\1__', restored_text)
    
    # 4. è™•ç†ä¸å®Œæ•´çš„ä»£ç¢¼å¡Šæ ¼å¼ï¼šCODE_BLOCK_n -> __CODE_BLOCK_n__
    restored_text = re.sub(r'CODE_BLOCK_(\d+)', r'__CODE_BLOCK_\1__', restored_text)
    
    # 5. è™•ç†ä¸­æ–‡æ•¸å­—çš„ä¸å®Œæ•´æ ¼å¼ï¼šCODE_BLOCK_ä¸­æ–‡æ•¸å­— -> __CODE_BLOCK_n__
    for chinese, arabic in chinese_numbers.items():
        restored_text = re.sub(f'CODE_BLOCK_{chinese}', f'__CODE_BLOCK_{arabic}__', restored_text)
    
    # 6. è™•ç†å¤šé‡åº•ç·šçš„æƒ…æ³ï¼š____CODE_BLOCK_n____ -> __CODE_BLOCK_n__
    restored_text = re.sub(r'_{3,}CODE_BLOCK_(\d+)_{3,}', r'__CODE_BLOCK_\1__', restored_text)
    
    # 7. è™•ç†ä¸­æ–‡æ•¸å­—çš„å¤šé‡åº•ç·šæƒ…æ³
    for chinese, arabic in chinese_numbers.items():
        restored_text = re.sub(f'_{3,}CODE_BLOCK_{chinese}_{3,}', f'__CODE_BLOCK_{arabic}__', restored_text)
    
    # æœ€å¾Œçš„æ¸…ç†ï¼Œç§»é™¤ä»»ä½•æ®˜ç•™çš„ä¿è­·ç¬¦è™Ÿ
    unicode_symbols = ['â¤', 'â™¥', 'â™¦', 'â™£', 'â™ ']
    for symbol in unicode_symbols:
        if symbol in restored_text:
            # è¨˜éŒ„è­¦å‘Šä½†ä¸ä¸­æ–·è™•ç†
            print(f"âš ï¸  è­¦å‘Šï¼šç™¼ç¾æœªè™•ç†çš„ä¿è­·ç¬¦è™Ÿ {symbol}")
    
    # ç¬¬6éšæ®µï¼šæœ€çµ‚çš„ Markdown æ ¼å¼æ¸…ç†
    # ä¿®å¾©ç²—é«”æ ¼å¼ä¸­çš„å¤šé¤˜ç©ºæ ¼ï¼ˆåŒ…æ‹¬ä¸å°ç¨±ç©ºæ ¼ï¼‰
    # 1. å…©é‚Šéƒ½æœ‰ç©ºæ ¼ï¼š** æ–‡å­— ** -> **æ–‡å­—**
    restored_text = re.sub(r'\*\*\s+(.+?)\s+\*\*', r'**\1**', restored_text)
    # 2. å·¦é‚Šæœ‰ç©ºæ ¼ï¼š** æ–‡å­—** -> **æ–‡å­—**
    restored_text = re.sub(r'\*\*\s+(.+?)\*\*', r'**\1**', restored_text)
    # 3. å³é‚Šæœ‰ç©ºæ ¼ï¼š**æ–‡å­— ** -> **æ–‡å­—**
    restored_text = re.sub(r'\*\*(.+?)\s+\*\*', r'**\1**', restored_text)
    
    # ä¿®å¾©åº•ç·šç²—é«”æ ¼å¼ä¸­çš„å¤šé¤˜ç©ºæ ¼ï¼ˆåŒ…æ‹¬ä¸å°ç¨±ç©ºæ ¼ï¼‰
    restored_text = re.sub(r'__\s+(.+?)\s+__', r'__\1__', restored_text)
    restored_text = re.sub(r'__\s+(.+?)__', r'__\1__', restored_text)
    restored_text = re.sub(r'__(.+?)\s+__', r'__\1__', restored_text)
    
    # ä¿®å¾©æ–œé«”æ ¼å¼ä¸­çš„å¤šé¤˜ç©ºæ ¼ï¼ˆä½†ä¸åŒ…æ‹¬ç²—é«” **ï¼‰
    restored_text = re.sub(r'(?<!\*)\*\s+(.+?)\s+\*(?!\*)', r'*\1*', restored_text)
    restored_text = re.sub(r'(?<!\*)\*\s+(.+?)\*(?!\*)', r'*\1*', restored_text)
    restored_text = re.sub(r'(?<!\*)\*(.+?)\s+\*(?!\*)', r'*\1*', restored_text)
    
    # ä¿®å¾©åº•ç·šæ–œé«”æ ¼å¼ä¸­çš„å¤šé¤˜ç©ºæ ¼ï¼ˆä½†ä¸åŒ…æ‹¬åº•ç·šç²—é«” __ï¼‰
    restored_text = re.sub(r'(?<!_)_\s+(.+?)\s+_(?!_)', r'_\1_', restored_text)
    restored_text = re.sub(r'(?<!_)_\s+(.+?)_(?!_)', r'_\1_', restored_text)
    restored_text = re.sub(r'(?<!_)_(.+?)\s+_(?!_)', r'_\1_', restored_text)
    
    return restored_text

def extract_text_segments(markdown_text):
    """
    å¾ Markdown æ–‡æœ¬ä¸­æå–éœ€è¦ç¿»è­¯çš„æ–‡å­—æ®µè½ï¼Œå®Œæ•´ä¿ç•™æ ¼å¼çµæ§‹å’Œæ›è¡Œ
    è¿”å›: (segments_to_translate, template_with_placeholders)
    """
    segments = []
    placeholder_counter = 0
    
    # ä¿ç•™åŸå§‹çš„æ›è¡Œç¬¦è™Ÿï¼Œä¸è¦æ›¿æ›æˆå…¶ä»–ç¬¦è™Ÿ
    result = markdown_text
    
    # å…ˆä¿è­·ä»£ç¢¼å¡Šå’Œå…§åµŒä»£ç¢¼ï¼Œé¿å…ç¿»è­¯
    code_blocks = []
    code_counter = 0
    
    def preserve_code_blocks(match):
        nonlocal code_counter
        placeholder = f"__CODE_BLOCK_{code_counter}__"
        code_blocks.append(match.group(0))
        code_counter += 1
        return placeholder
    
    # ä¿è­·ä»£ç¢¼å¡Šï¼ˆä¸‰å€‹åå¼•è™Ÿï¼‰
    result = re.sub(r'```[\s\S]*?```', preserve_code_blocks, result)
    # ä¿è­·å…§åµŒä»£ç¢¼ï¼ˆå–®å€‹åå¼•è™Ÿï¼‰
    result = re.sub(r'`[^`\n]+`', preserve_code_blocks, result)
    
    # è™•ç†æ¨™é¡Œ
    def replace_heading(match):
        nonlocal placeholder_counter
        heading_symbols = match.group(1)  # # ## ### ç­‰
        heading_text = match.group(2).strip()
        if heading_text:
            placeholder = f"__TRANSLATE_PLACEHOLDER_{placeholder_counter}__"
            segments.append(heading_text)
            placeholder_counter += 1
            return f"{heading_symbols} {placeholder}"
        return match.group(0)
    
    # è™•ç†æ¨™é¡Œ (# ## ###)
    result = re.sub(r'^(#{1,6})\s+(.+)$', replace_heading, result, flags=re.MULTILINE)
    
    # è™•ç†åˆ—è¡¨é …ç›®
    def replace_list_item(match):
        nonlocal placeholder_counter
        list_marker = match.group(1)  # - * + â€¢ æˆ– 1. 2. ç­‰
        list_text = match.group(2).strip()
        if list_text and not list_text.startswith(('__TRANSLATE_PLACEHOLDER_', '__CODE_BLOCK_')):
            placeholder = f"__TRANSLATE_PLACEHOLDER_{placeholder_counter}__"
            segments.append(list_text)
            placeholder_counter += 1
            return f"{list_marker}{placeholder}"
        return match.group(0)
    
    # è™•ç†ç„¡åºåˆ—è¡¨ (æ”¯æŒ -, *, +, â€¢ ç­‰ç¬¦è™Ÿ)
    result = re.sub(r'^(\s*[-*+â€¢]\s+)(.+)$', replace_list_item, result, flags=re.MULTILINE)
    # è™•ç†æœ‰åºåˆ—è¡¨
    result = re.sub(r'^(\s*\d+\.\s+)(.+)$', replace_list_item, result, flags=re.MULTILINE)
    
    # è™•ç†å¼•ç”¨æ–‡å­—
    def replace_quote(match):
        nonlocal placeholder_counter
        quote_marker = match.group(1)  # >
        quote_text = match.group(2).strip()
        if quote_text and not quote_text.startswith(('__TRANSLATE_PLACEHOLDER_', '__CODE_BLOCK_')):
            placeholder = f"__TRANSLATE_PLACEHOLDER_{placeholder_counter}__"
            segments.append(quote_text)
            placeholder_counter += 1
            return f"{quote_marker} {placeholder}"
        return match.group(0)
    
    # è™•ç†å¼•ç”¨å¡Š
    result = re.sub(r'^(>\s*)(.+)$', replace_quote, result, flags=re.MULTILINE)
    
    # è™•ç†ä¸€èˆ¬æ®µè½æ–‡å­—ï¼ˆä¸åœ¨ä»¥ä¸Šæ ¼å¼ä¸­çš„æ–‡å­—ï¼‰
    # ä½¿ç”¨æŒ‰è¡Œè™•ç†æ–¹å¼ï¼Œå®Œæ•´ä¿ç•™åŸå§‹çš„æ›è¡Œå’Œç©ºè¡Œ
    lines = result.split('\n')  # ä¿ç•™åŸå§‹çš„æ›è¡Œåˆ†éš”
    processed_lines = []
    
    for line_index, original_line in enumerate(lines):
        line = original_line.strip()
        
        # å®Œæ•´ä¿ç•™ç©ºè¡Œå’Œå·²è™•ç†çš„è¡Œ
        if not line or line.startswith(('__TRANSLATE_PLACEHOLDER_', '__CODE_BLOCK_')):
            processed_lines.append(original_line)  # ä¿ç•™åŸå§‹è¡Œï¼ŒåŒ…æ‹¬ç©ºè¡Œ
            continue
            
        # è·³éå·²è™•ç†çš„æ¨™é¡Œã€åˆ—è¡¨ã€å¼•ç”¨ã€è¡¨æ ¼ç­‰
        if (line.startswith('#') or 
            re.match(r'^\s*[-*+â€¢]\s+', line) or  # æ”¯æŒæ›´å¤šåˆ—è¡¨ç¬¦è™Ÿ
            re.match(r'^\s*\d+\.\s+', line) or 
            line.startswith('>') or 
            line.startswith('|') or
            re.match(r'^[-=]+$', line) or  # æ¨™é¡Œåº•ç·š
            re.match(r'^\s*$', line)):  # ç©ºè¡Œ
            processed_lines.append(original_line)  # ä¿ç•™åŸå§‹è¡Œ
            continue
        
        # è™•ç†ä¸€èˆ¬æ®µè½æ–‡å­—
        if line and not re.match(r'^[\s\*\-\+=|>]*$', line):  # ä¸æ˜¯åªæœ‰æ ¼å¼ç¬¦è™Ÿçš„è¡Œ
            placeholder = f"__TRANSLATE_PLACEHOLDER_{placeholder_counter}__"
            segments.append(line)  # å„²å­˜å»é™¤ç©ºæ ¼çš„æ–‡å­—å…§å®¹
            placeholder_counter += 1
            # å®Œæ•´ä¿ç•™åŸå§‹ç¸®é€²å’Œæ ¼å¼
            leading_spaces = len(original_line) - len(original_line.lstrip())
            processed_lines.append(' ' * leading_spaces + placeholder)
        else:
            processed_lines.append(original_line)  # ä¿ç•™åŸå§‹è¡Œ
    
    # é‡æ–°çµ„åˆï¼Œä¿ç•™æ‰€æœ‰åŸå§‹æ›è¡Œ
    result = '\n'.join(processed_lines)
    
    # æ¢å¾©ä»£ç¢¼å¡Š
    for i, code_block in enumerate(code_blocks):
        result = result.replace(f"__CODE_BLOCK_{i}__", code_block)
    
    return segments, result

def reconstruct_markdown(template, translated_segments):
    """
    å°‡ç¿»è­¯å¾Œçš„æ–‡å­—æ®µè½é‡æ–°çµ„åˆæˆ Markdown æ ¼å¼
    """
    result = template
    for i, translated_text in enumerate(translated_segments):
        placeholder = f"__TRANSLATE_PLACEHOLDER_{i}__"
        result = result.replace(placeholder, translated_text.strip())
    return result

def hakka_translate(text, index):
    """
    ç¿»è­¯ Markdown æ–‡æª”ï¼Œä¿ç•™æ ¼å¼çµæ§‹
    """
    # Validate environment variables
    url = os.getenv("HAKKA_TRANS_URL_BASE")
    transUrl = os.getenv("HAKKA_TRANS_URL_TRANS")
    username = os.getenv("HAKKA_TRANS_USERNAME")
    password = os.getenv("HAKKA_TRANS_PASSWORD")

    if not url or not transUrl or not username or not password:
        raise ValueError("Missing one or more required environment variables: HAKKA_TRANS_URL_BASE, HAKKA_TRANS_URL_TRANS, HAKKA_TRANS_USERNAME, HAKKA_TRANS_PASSWORD")

    try:
        # 1. æå–éœ€è¦ç¿»è­¯çš„æ–‡å­—æ®µè½
        segments_to_translate, markdown_template = extract_text_segments(text)
        
        if not segments_to_translate:
            # å¦‚æœæ²’æœ‰éœ€è¦ç¿»è­¯çš„å…§å®¹ï¼Œç›´æ¥è¿”å›åŸæ–‡
            return {
                "success": True,
                "translated_text": text,
                "original_segments": [],
                "translated_segments": []
            }
        
        print(f"Found {len(segments_to_translate)} segments to translate:")
        for i, segment in enumerate(segments_to_translate):
            print(f"  Segment {i}: {segment[:50]}...")
        
        # Authenticate and get token
        payload = json.dumps({
            "username": username,
            "password": password,
            "rememberMe": 0
        })
        headers = {
            'Content-Type': 'application/json'
        }
        response = requests.request("POST", url, headers=headers, data=payload, verify=False)
        response.raise_for_status()
        token = response.json().get('token')
        if not token:
            raise ValueError("Authentication failed: No token received")
        print(f"Authentication successful, token: {token[:20]}...")

        # 2. é€æ®µç¿»è­¯æ–‡å­—å…§å®¹
        translated_segments = []
        translation_headers = {
            'Authorization': 'Bearer ' + token,
            'Content-Type': 'application/json'
        }
        
        for i, segment in enumerate(segments_to_translate):
            try:
                print(f"\nğŸ”„ ç¿»è­¯æ®µè½ {i+1}/{len(segments_to_translate)}: '{segment[:50]}{'...' if len(segment) > 50 else ''}' ")
                
                # åœ¨ç¿»è­¯å‰ä¿è­· Markdown æ ¼å¼ç¬¦è™Ÿ
                protected_segment = protect_markdown_symbols(segment)
                print(f"ğŸ›¡ï¸  ä¿è­·å¾Œ: '{protected_segment[:50]}{'...' if len(protected_segment) > 50 else ''}'")
                
                payload = json.dumps({
                    "input": protected_segment
                })
                response = requests.request("POST", transUrl, headers=translation_headers, data=payload, verify=False)
                response.raise_for_status()
                
                translation_result = response.json()
                print(f"ğŸ“¥ åŸå§‹ç¿»è­¯ API éŸ¿æ‡‰: {translation_result}")
                
                # å˜—è©¦å¾ä¸åŒå­—æ®µä¸­æå–ç¿»è­¯çµæœ
                translated_text = None
                
                if 'output' in translation_result:
                    translated_text = translation_result['output']
                    print(f"âœ… å¾ 'output' å­—æ®µæå–: '{translated_text}'")
                elif 'result' in translation_result:
                    translated_text = translation_result['result']
                    print(f"âœ… å¾ 'result' å­—æ®µæå–: '{translated_text}'")
                elif 'translation' in translation_result:
                    translated_text = translation_result['translation']
                    print(f"âœ… å¾ 'translation' å­—æ®µæå–: '{translated_text}'")
                else:
                    # å˜—è©¦ç›´æ¥ä½¿ç”¨è¿”å›çš„å­—ç¬¦ä¸²
                    translated_text = str(translation_result).strip('"\'')
                    print(f"âš ï¸  ä½¿ç”¨å­—ç¬¦ä¸²è½‰æ›: '{translated_text}'")
                
                # æª¢æŸ¥ç¿»è­¯çµæœæ˜¯å¦ç‚ºç©ºæˆ–ç„¡æ•ˆ
                if not translated_text or translated_text.strip() == "" or translated_text.strip() == "null" or translated_text.strip() == "None":
                    print(f"âŒ ç¿»è­¯çµæœç‚ºç©ºæˆ–ç„¡æ•ˆ ('{translated_text}')ï¼ä¿ç•™åŸæ–‡: '{segment}'")
                    translated_text = segment
                elif len(translated_text.strip()) < 3:  # ç¿»è­¯çµæœå¤ªçŸ­ï¼Œå¯èƒ½æ˜¯éŒ¯èª¤
                    print(f"âš ï¸  ç¿»è­¯çµæœå¤ªçŸ­ ('{translated_text}')ï¼Œå¯èƒ½æœ‰èª¤ï¼ä¿ç•™åŸæ–‡: '{segment}'")
                    translated_text = segment
                elif translated_text.strip() == segment.strip():
                    print(f"âš ï¸  ç¿»è­¯çµæœèˆ‡åŸæ–‡ç›¸åŒï¼Œå¯èƒ½ç¿»è­¯å¤±æ•—")
                    # å³ä½¿ç¿»è­¯å¤±æ•—ï¼Œä¹Ÿè¦æ¢å¾©æ ¼å¼ç¬¦è™Ÿ
                    translated_text = restore_markdown_symbols(translated_text)
                else:
                    print(f"âœ… ç¿»è­¯æˆåŠŸ: '{segment[:30]}...' â†’ '{translated_text[:30]}...'")
                    # æ¢å¾© Markdown æ ¼å¼ç¬¦è™Ÿ
                    translated_text = restore_markdown_symbols(translated_text)
                    print(f"ğŸ”§ æ¢å¾©æ ¼å¼å¾Œ: '{translated_text[:50]}{'...' if len(translated_text) > 50 else ''}'")
                
                translated_segments.append(translated_text)
                
            except requests.exceptions.RequestException as e:
                print(f"âŒ ç¶²çµ¡è«‹æ±‚å¤±æ•— - æ®µè½ {i}: {e}")
                print(f"   ä¿ç•™åŸæ–‡: '{segment}'")
                translated_segments.append(segment)
            except json.JSONDecodeError as e:
                print(f"âŒ JSON è§£æå¤±æ•— - æ®µè½ {i}: {e}")
                print(f"   ä¿ç•™åŸæ–‡: '{segment}'")
                translated_segments.append(segment)
            except Exception as e:
                print(f"âŒ æœªçŸ¥éŒ¯èª¤ - æ®µè½ {i}: {type(e).__name__}: {e}")
                print(f"   ä¿ç•™åŸæ–‡: '{segment}'")
                translated_segments.append(segment)
        
        # 3. é‡æ–°çµ„åˆ Markdown æ–‡æª”
        final_translated_text = reconstruct_markdown(markdown_template, translated_segments)
        
        # Save translation result for debugging
        output_dir = 'temp_trans'
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜è©³ç´°çš„ç¿»è­¯çµæœ
        detailed_result = {
            "success": True,
            "original_text": text,
            "translated_text": final_translated_text,
            "original_segments": segments_to_translate,
            "translated_segments": translated_segments,
            "markdown_template": markdown_template
        }
        
        output_path = os.path.join(output_dir, f'translation_{index}.json')
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(detailed_result, f, ensure_ascii=False, indent=4)
        
        print(f"Translation completed successfully. Saved to {output_path}")
        
        # è¿”å›ç¿»è­¯çµæœï¼ˆèˆ‡å‰ç«¯æœŸæœ›æ ¼å¼åŒ¹é…ï¼‰
        return {
            "success": True,
            "translatedText": final_translated_text,  # å‰ç«¯æœŸæœ›çš„å­—æ®µå
            "output": final_translated_text,  # ä¿ç•™å‘å¾Œå…¼å®¹æ€§
            "original_segments": segments_to_translate,
            "translated_segments": translated_segments
        }

    except requests.exceptions.RequestException as e:
        raise RuntimeError(f"API request failed: {e}")
    except ValueError as e:
        raise RuntimeError(f"Error: {e}")
    except Exception as e:
        raise RuntimeError(f"Unexpected error during translation: {e}")
